{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multitask learning on the CIFAR-100 dataset using TensorFlow for image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the CIFAR-100 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the shared feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_layer = tf.keras.layers.Input(shape=(32, 32, 3))\n",
    "conv_layer_1 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='same')(input_layer)\n",
    "conv_layer_2 = tf.keras.layers.Conv2D(32, (3,3), activation='relu')(conv_layer_1)\n",
    "maxpool_layer = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(conv_layer_2)\n",
    "flatten_layer = tf.keras.layers.Flatten()(maxpool_layer)\n",
    "shared_layer_1 = tf.keras.layers.Dense(128, activation='relu')(flatten_layer)\n",
    "shared_layer_2 = tf.keras.layers.Dense(64, activation='relu')(shared_layer_1)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the first output head for fine-grained classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fine_output = tf.keras.layers.Dense(100, activation='softmax', name='fine_output')(shared_layer_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the second output head for coarse-grained classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coarse_output = tf.keras.layers.Dense(20, activation='softmax', name='coarse_output')(shared_layer_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model with two output heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.models.Model(inputs=input_layer, outputs=[fine_output, coarse_output])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model with two loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer='adam', loss={'fine_output': 'sparse_categorical_crossentropy', 'coarse_output': 'sparse_categorical_crossentropy'}, metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, {'fine_output': y_train, 'coarse_output': y_train // 5}, validation_data=(x_test, {'fine_output': y_test, 'coarse_output': y_test // 5}), epochs=10, metrics={'fine_output': 'accuracy', 'coarse_output': 'accuracy'})\n",
    "\n",
    "fine_accuracy = history.history['fine_output_accuracy']\n",
    "coarse_accuracy = history.history['coarse_output_accuracy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
